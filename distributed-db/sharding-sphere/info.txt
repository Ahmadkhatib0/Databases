for databases we at the Apache ShardingSphere community are proponents of what we call Database Plus 
  which in simple terms means software that allows you to manage and improve any type of database, 
  even to integrate different database types into the same system.

some organizations have already started to adopt a cloud-first strategy, which simply means including 
  or moving to a cloud-based solution at the expense of a strategy built around in-house data centers. 
  This new IT trend is going to move the databases to the cloud as a Database-as-a-Service (DBaaS)

NewSQL can be defined as a type of relational database management system (RDBMS)
  looking to make NoSQL systems scalable for online transaction processing (OLTP)
  tasks, all while keeping the ACID qualities of a traditional database system.

A transparent sharding middleware splits a database into multiple shards that are stored across a 
  cluster of a single-node DBMS instance, just as Apache ShardingSphere does.
  Sharding middleware exists to allow a user – or in this case, an organization – to split
  a database into multiple shards to be stored across multiple single-node DBMS instances,

Data sharding
  When a large database table is split into multiple small tables, shards are created. The newly created 
  tables are called shards or partitions. These shards are stored across multiple nodes to work efficiently, 
  improving scalability and performance. This type of scalability is known as horizontal scalability. Sharding 
  eventually helps database administrators such as yourself utilize computing resources in the most 
  efficient way possible and is collectively known as database optimization.

Partitioning refers to a database that has been broken down into different subsets but is still stored 
  within a single database. This single database is sometimes referred to as the database instance. 
  So what is the difference between sharding and partitioning? Both sharding and partitioning include 
  breaking large data sets into smaller ones. But a key difference is that sharding implies that the 
  breakdown of data is spread across multiple computers, either as horizontal partitioning or vertical.

The primary feature of Apache ShardingSphere is to capture database access entry and provide 
  additional features transparently, such as redirect (sharding, read/write splitting, and shadow 
  databases), transform (data encrypting and masking), authentication (security, auditing, and authority), 
  and governance (circuit breaker, access limitation and analysis, QoS, and observability).

As a developer, you are allowed to create custom features without having to modify the source code of 
  Apache ShardingSphere. The pluggable architecture of Apache ShardingSphere adopts a microkernel and 
  a three-layer pluggable mode. Apache ShardingSphere's architecture is directed toward top-level
  APIs, so the kernel cannot be aware of the existence of specific functions. If you don't need a 
  function, all you have to do is delete the dependency – it'll have zero impact on the system.

The architectural possibilities at your disposal: 
  Database middleware requires two things: a driver to access the database and an independent proxy.
  Since no adaptor of an architecture model is flawless, Apache ShardingSphere chose to develop multiple 
  adaptors. ShardingSphere-JDBC and ShardingSphere-Proxy are two independent products, but you can choose 
  what we interchangeably refer to as the hybrid model or mixed deployment, and deploy them together. 
  They both provide dozens of enhanced features that see databases as storage nodes that apply to 
  scenarios such as Java isomorphism, heterogeneous languages, cloud-native, and more.

ShardingSphere-JDBC:
  Being the predecessor and eventually the first client of the Apache ShardingSphere ecosystem, 
  ShardingSphere-JDBC is a lightweight Java framework that provides extra services at the Java JDBC 
  layer. ShardingSphere-JDBC's flexibility will be very helpful to you for the following reasons:
  • It applies to any ORM framework based on JDBC, such as JPA, Hibernate, Mybatis, and Spring JDBC 
    Template. It can also be used directly with JDBC. 
  . It supports any third-party database connection pool, such as DBCP, C3P0, BoneCP, and HikariCP.
  • It supports any database that meets JDBC's standards. Currently, ShardingSphere JDBC supports 
    MySQL, PostgreSQL, Oracle, SQLServer, and any other databases that support JDBC access.

ShardingSphere-Proxy: 
  ShardingSphere-Proxy was the second client to join the Apache ShardingSphere ecosystem. A transparent 
  database proxy, ShardingSphere-Proxy provides a database server that encapsulates the database binary 
  protocol to support heterogeneous languages. The proxy is as follows:
  • Transparent to applications; it can be used directly as MySQL/PostgreSQL. 
  • Applicable to any kind of client that is compatible with the MySQL/PostgreSQL protocol.
  

Comparing ShardingSphere-JDBC and ShardingSphere-Proxy: 
  ShardingSphere-Proxy has a distributed computing module and can be deployed independently. It 
  applies to applications with multidimensional data calculation, which are less sensitive to delay 
  but consume more computing resources.

Hybrid deployment
  Adopting a decentralized architecture, ShardingSphere-JDBC applies to Java-based high-performing and 
  lightweight OLTP applications. On the other hand, ShardingSphere-Proxy provides static entry and 
  comprehensive language support and is suitable for OLAP applications, as well as managing and 
  operating sharding databases. This results in a ShardingSphere ecosystem that consists of multiple 
  endpoints. Thanks to a unified sharding strategy and the hybrid integration of ShardingSphere-JDBC and
  ShardingSphere-Proxy, a multi-scenario-compatible application system can be built with ShardingSphere.

ShardingSphere is built on a three-layer logic: 
  The first layer includes the kernel with critical features working in the background to make sure 
  everything runs properly on your database. These critical features are a transaction engine, a query 
  optimizer, distributed governance, a storage engine, an authority engine, and a scheduling engine.

Under the distributed database architecture with storage separated from compute, the stateful storage 
  layer designated for data persistence and push-down computing cannot be expanded as desired. To 
  avoid data loss, it's of great importance to keep multiple copies of data and to adopt a dynamic 
  migration solution to scale out.
The stateless computing layer, on the other hand, is created for distributed query plan generation, 
  distributed transaction, and distributed aggregate calculation, allowing users to horizontally scale 
  computing capabilities. Since computing nodes are scalable, we decided to build the load balancer in 
  front of the database clusters. Naturally, it becomes the centralized point of entry.

A Sidecar model refers to the addition of a load balancer on each application server. Its
  life cycle is consistent with that of the application itself: when an application starts, so does
  its load balancer; when an application is destroyed, it will disappear as well.
  Now that every application is equipped with its own load balancer, the HA of the load
  balancer is also ensured. This method also minimizes performance waste because the load
  balancer and the application are deployed in the same physical container, which means the
  Remote Procedure Call (RPC) is converted into Inter-Process Communication (IPC).
  Along with better performance and HA, Sidecar also has applications loosely coupled to
  its database software development kit (SDK), and therefore operations (Ops) teams can freely upgrade 
  Sidecar or databases since the design shields the business application from perceiving the upgrade.
  The popular Service Mesh concept actually uses Sidecar as its dashboard to process east-
  west and north-south traffic in the system, and also leverages the Control Panel to issue
  instructions to the dashboard in order to control traffic or complete transparent upgrades.

Kubernetes is a good way to lower Sidecar deployment and management costs. It can
  put a load balancer and the application image in a Pod or use a DaemonSet to simplify
  the deployment process. After each Pod starts running, Sidecar can be understood as an inseparable 
  part of the operating system. The application accesses the database through localhost.

When it comes to the benefits of Database Plus, we could summarize them with the following points:
• Standardized layer to hide different usages for various databases.
• Noticeably reduce the effect of varying database replacement.
• Supply enhanced functions to solve these annoying problems.
• Assemble different feature plugins for your specific cases.
• Allow users to utilize their customized implementations for most kernel phases.


When we talk about sharding, we refer to splitting data that is stored in one database
  in a way that allows it to be stored in multiple databases or tables, in order to improve performance 
  and data availability. Sharding can usually be divided into database sharding and table sharding.
  Database sharding can effectively reduce visits to a single database and thereby reduce
  database pressure. Although table sharding cannot reduce database pressure, it can
  reduce the data amount of a single table to avoid query performance decrease caused
  by an increase in index depth. At the same time, sharding can also convert distributed
  transactions into local transactions, avoiding the complexity of distributed transactions.

Elastic migration
  Considering a hypothetical situation where our business data is growing quickly, then
  according to widespread database professionals' belief, the backend database could be the
  bottleneck. How could we prevent or resolve this? Elastic migration could help. Just add more 
  database instances and configure more shards in Apache ShardingSphere, then migration will be 
  scheduled and a scaling job will be created to do the migration. The scaling job includes four 
  phases: a preparation phase, an inventory phase, an incremental phase, and a switching phase. 

Shadow DB:
  The industry usually chooses online full-link stress testing—that is, performing stress
  testing in a production environment. To ensure the reliability and integrity of production
  data to prevent data pollution, data isolation has become a key and difficult point.
  The Shadow DB function is ShardingSphere's solution for isolating the pressure-test data
  at the database level in a full-link pressure-test scenario.

APM: 
  ShardingSphere's APM feature provides metrics and tracing data to a framework or server
  for implementing the observability of ShardingSphere. It's based on Byte Buddy, which is
  a runtime code generator used by Java agents, and it's developed this way to support zero
  intrusion into other modules' code and decoupling it from core functions.

The microkernel processing workflow involves two standard modules, SQL Parser and SQL Binder. These 
  two modules are developed to identify specific SQL characteristics and then, based on the results, 
  the SQL execution workflow is divided into a simple push-down engine and a SQL federation engine.
  The pluggable SPI is the abstract top-level interface of Apache ShardingSphere's core
  process. The microkernel does not work for rule implementation, and it just calls a class
  registered in the system that implements an interface step by step. Along with the SQL
  executor, all SPIs use the decorator design pattern to support feature combinations.

The SQL parser analyzes basic information—for example, it checks whether SQL contains
  related queries and subqueries. SQL binder analyzes the relations between logical tables
  and physical databases to determine the possibility of cross-database-source operation
  for the SQL request. When the full SQL can be pushed down to the database storage node
  after operations such as modifying a logical table or executing information completion,
  it's time to adopt Simple Push Down Engine to ensure maximum compatibility with SQL.
  Otherwise, if the SQL involves cross-database association and a cross-database subquery,
  then SQL Federation Engine is used to achieve better system performance during the
  process of operating distributed table association

Simple Push Down Engine
  For Apache ShardingSphere, Simple Push Down Engine is an old feature, and it is
  applicable to scenarios where database native computing and storage capabilities need to
  be fully reused to maximize SQL compatibility and stabilize query responses. It is perfectly
  compatible with an application system based on the Share Everything architecture model.

SQL Federation Engine: 
  SQL Federation Engine is a newly developed engine in Apache ShardingSphere, but its development iteration 
  is quite frequent now. The engine is suitable for cross-database associated queries and sub-queries, 
  It can fully support a multi-dimensional elastic query system applicable to the Share-Nothing 
  distributed architecture model. Apache ShardingSphere will continue to improve the query optimizer 
  model, trying to migrate more SQLs from Simple Push Down Engine to SQL Federation Engine.
  The major difference between SQL Federation Engine and Simple Push Down
  Engine is the SQL optimizer, which optimizes the AST Node by leveraging a rule-based
  optimizer (RBO) and cost-based optimizer (CBO) to generate a Query Plan Tree.
  Therefore, to obtain data from the storage node, it does not rely on the original SQL but
  instead can leverage the query plan tree, regenerate a new SQL that can be executed on
  a single data node, and later send this to the storage node according to the routing result.






